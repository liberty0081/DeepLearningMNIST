{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NeuralNetworkLayer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNzPKeKft6qSypMZZntn0hN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"4UEbvDDs-VJM"},"source":["import numpy as np\n","\n","class Softmax2CrossEntropy():\n","    def __init__(self):\n","        self.y    = None\n","        self.t    = None\n","        self.flag = False\n","\n","    def forward(self, x, t):\n","        self.y = np.empty(x.shape)\n","        self.t = t\n","        \n","        for i in range(self.y.shape[0]):\n","            c = np.amax(x[i])\n","            self.y[i] = np.exp(x[i] - c)/(np.sum(np.exp(x[i] - c)))\n","\n","        self.flag = True\n","        \n","        return -(np.sum(self.t*np.log(self.y)))/self.t.shape[0]\n","\n","    def test_forward(self, x):\n","        y = np.empty(x.shape)\n","\n","        for i in range(y.shape[0]):\n","            c = np.amax(x[i])\n","            y[i] = np.exp(x[i] - c)/(np.sum(np.exp(x[i] - c)))\n","        \n","        return y\n","\n","    def test_loss(self, x, t):\n","        y = self.test_forward(x)\n","        return -(np.sum(t*np.log(y)))/t.shape[0]\n","\n","    def backward(self):\n","        if self.flag:\n","            self.flag = False\n","            return (self.y - self.t)/self.t.shape[0]\n","        \n","        else:\n","            raise Exception(\"you have to run forward method before\")\n","            \n","class Swish():\n","    def __init__(self):\n","        self.x    = None\n","        self.flag = False\n","\n","    def forward(self, x):\n","        self.x    = x\n","        self.flag = True\n","        return self.x/(1 + np.exp(-self.x))\n","\n","    def test_forward(self, x):\n","        return x/(1 + np.exp(-x))\n","\n","    def backward(self, delta):\n","        if self.flag:\n","            self.flag = False\n","            return delta*((1 + np.exp(-self.x)*(1 + self.x))/((1 + np.exp(-self.x))**2))\n","        \n","        else:\n","            raise Exception(\"you have to run forward method before\")\n","\n","class ReLU():\n","    def __init__(self):\n","        self.x    = None\n","        self.flag = False\n","\n","    def forward(self, x):\n","        self.x    = x\n","        self.flag = True\n","        return np.maximum(0, self.x)\n","\n","    def test_forward(self, x):\n","        return np.maximum(0, x)\n","\n","    def backward(self, delta):\n","        if self.flag:\n","            self.flag = False\n","            return delta*((self.x > 0).astype(np.int))\n","        \n","        else:\n","            raise Exception(\"you have to run forward method before\")\n","\n","class Sigmoid():\n","    def __init__(self):\n","        self.x    = None\n","        self.flag = False\n","\n","    def forward(self, x):\n","        self.x    = x\n","        self.flag = True\n","        return 1/(1 + np.exp(-self.x))\n","\n","    def test_forward(self, x):\n","        return 1/(1 + np.exp(-x))\n","\n","    def backward(self, delta):\n","        if self.flag:\n","            self.flag = False\n","            return delta*((np.exp(-self.x))/(1 + np.exp(-self.x))**2)\n","        \n","        else:\n","            raise Exception(\"you have to run forward method before\")\n","\n","class Affine():\n","    def __init__(self, inputSize, outputSize):\n","        self.data  = {\"IN\":inputSize, \"OUT\":outputSize}\n","        self.W     = np.random.randn(self.data[\"IN\"], self.data[\"OUT\"])*0.1\n","        self.b     = np.random.randn(self.data[\"OUT\"])*0.1\n","        self.dW    = np.zeros_like(self.W)\n","        self.db    = np.zeros_like(self.b)\n","        self.delta = None\n","        self.x     = None\n","        self.flag  = False \n","\n","\n","    def forward(self, x):\n","        self.x    = x\n","        self.flag = True\n","\n","        return np.dot(self.x, self.W) + self.b\n","\n","    def test_forward(self, x):\n","        return np.dot(x, self.W) + self.b\n","\n","    def backward(self, delta):\n","        if self.flag:\n","            self.flag = False\n","            self.delta = delta\n","            self.dW = np.dot(self.x.T, self.delta)\n","            self.db = np.sum(self.delta, axis = 0)\n","\n","            return np.dot(self.delta, self.W.T)\n","        \n","        else:\n","            raise Exception(\"you have to run forward method before\")\n","\n","class BatchNorm():\n","    def __init__(self, inputSize):\n","        self.W      = np.ones(inputSize)\n","        self.b      = np.zeros(inputSize)\n","        self.mu     = None\n","        self.sigma  = None\n","        self.m      = None\n","        self.dW     = None\n","        self.db     = None\n","        self.x      = None\n","        self.x_hat  = None\n","        self.delta  = None\n","        self.xc     = None\n","        self.std    = None\n","        \n","        self.flag   = False\n","\n","    def forward(self, x):\n","        self.x     = x\n","        self.m     = self.x.shape[0]\n","        self.flag  = True\n","\n","        self.mu    = np.sum(self.x, axis = 0)/self.m\n","        self.xc    = self.x - self.mu\n","        self.sigma = np.sum((self.xc)**2, axis = 0)/self.m\n","        self.std   = np.sqrt(self.sigma + 1e-7)\n","        self.x_hat = self.xc/self.std\n","\n","        return self.W*self.x_hat + self.b\n","\n","    def test_forward(self, u):\n","        x     = u\n","        m     = x.shape[0]\n","\n","        mu    = np.sum(x, axis = 0)/m\n","        sigma = np.sum((x - mu)**2, axis = 0)/m\n","        x_hat = ((x - mu)/np.sqrt(sigma + 1e-7))\n","\n","        return self.W*x + self.b\n","\n","    def backward(self, delta):\n","        if self.flag:\n","            self.flag    = False\n","\n","            self.db      = np.sum(delta, axis = 0)\n","            self.dW      = np.sum(delta*self.x_hat, axis = 0)\n","\n","            dxn  = self.W*delta\n","            dxc  = dxn/self.std\n","            dstd = -np.sum((dxn*self.xc)/(self.std*self.std), axis = 0)\n","            dvar = 0.5*dstd/self.std\n","            dxc += (2.0/self.m)*self.xc*dvar\n","            dmu  = np.sum(dxc, axis = 0)\n","            dx   = dxc - dmu/self.m\n","\n","            return dx \n","\n","            \"\"\"\n","            f0           = self.sigma + 1e-7\n","            f1           = self.x - self.mu\n","            f2           = np.sum(-f1, axis = 0)/self.m\n","            f3           = 2*(f1 + f2)/self.m\n","            f4           = 1/(2*np.sqrt(f0))\n","            f5           = f3*f4\n","\n","            row_size1    = f5.shape[0]\n","            column_size1 = f5.shape[1]\n","            f6           = f5.T.flatten()\n","\n","            f7           = np.zeros(column_size1*row_size1*column_size1)\n","            indx1       = (np.arange(f5.size)*column_size1 + np.floor(np.arange(f5.size)/row_size1)).astype(int)\n","            f7[indx1]    = f6\n","            f8           = f7.reshape(column_size1, row_size1, column_size1)\n","            f9           = np.dot(f8, f1.T)\n","\n","            f10          = np.identity(self.m) - 1/self.m\n","            f11          = np.resize(f10, (f0.shape[0], f10.shape[0], f10.shape[1]))\n","            f12          = np.sqrt(f0)\n","            f13          = f12[:, np.newaxis, np.newaxis]\n","            f14          = f13*f11\n","\n","            f15          = f14 - f9\n","            f16          = (1/f0)[:, np.newaxis, np.newaxis]\n","            f17          = f16*f15\n","            f18          = np.dot(f17, delta)\n","\n","            row_size2    = f18.shape[1]\n","            column_size2 = f18.shape[2]\n","            indx2        = (np.arange(row_size2*column_size2)*column_size2 + np.floor(np.arange(row_size2*column_size2)/row_size2)).astype(int)\n","            f19          = f18.flatten()\n","            f20          = f19[indx2]\n","            f21          = f20.reshape(column_size2, row_size2).T + 0\n","            \n","            return f21\n","            \"\"\"\n","\n","        else:\n","            raise Exception(\"you have to run forward method before\")"],"execution_count":null,"outputs":[]}]}