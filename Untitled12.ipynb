{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled12.ipynb","provenance":[],"authorship_tag":"ABX9TyM9V3x4b0i5OoD5CEqnq0ok"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"vGTRJamxXozc","executionInfo":{"status":"error","timestamp":1634442635156,"user_tz":-540,"elapsed":447,"user":{"displayName":"Liberty0079","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05455691760143426829"}},"outputId":"add19c05-510d-4c96-e03c-2847653f4ea7"},"source":["import sys, os\n","sys.path.append(os.pardir)\n","from dataset.mnist import load_mnist\n","import numpy as np\n","\n","def sigmoid(x):\n","    return 1/(1 + np.exp(-x))\n","\n","def softmax(x):\n","    c = np.amax(x)\n","    return np.exp(x - c)/(np.sum(np.exp(x - c)))\n","\n","def crossEntropyError(y, t):\n","    if y.shape != t.shape:\n","        return\n","    \n","    elif y.ndim == 1 or t.ndim == 1:\n","        y = y.reshape(1, y.size)\n","        t = t.reshape(1, t.size)\n","    \n","    batchSize = y.shape[0]\n","    return -np.sum(t*np.log(y))/batchSize\n","\n","class TwoLayerNet():\n","    \n","    def __init__(self, inputSize, hidenSize, outputSize):\n","        self.W1 = np.random.randn(inputSize, hidenSize)\n","        self.W2 = np.random.randn(hidenSize, outputSize)\n","        self.b1 = np.random.randn(hidenSize)\n","        self.b2 = np.random.randn(outputSize)\n","        self.outputSize = outputSize\n","        \n","    def output(self, x):\n","        if x.ndim == 1:\n","            x = x.reshape(1, x.size)\n","            y = np.empty((1, self.outputSize))\n","        else:\n","            y = np.empty((x.shape[0], self.outputSize))\n","            \n","        for i in range(x.shape[0]):\n","            z1 = np.dot(x[i], self.W1) + self.b1\n","            z1 = sigmoid(z1)\n","            v1 = np.dot(z1, self.W2) + self.b2\n","            v2 = sigmoid(v1)\n","            y[i] = softmax(v2)\n","        return y\n","    \n","    def accuracy(self, x, t):\n","        y = self.output(x)\n","        a = np.argmax(y, axis=1)\n","        b = np.argmax(t, axis=1)\n","        acc = float(np.sum(a == b))/float(x.shape[0])\n","        return acc\n","    \n","    def lossFunction(self, x, t):\n","        y = self.output(x)\n","        return crossEntropyError(y, t)\n","    \n","    def grad(self, x, t):\n","        g_W1 = np.zeros_like(self.W1)\n","        g_W2 = np.zeros_like(self.W2)\n","        g_b1 = np.zeros_like(self.b1)\n","        g_b2 = np.zeros_like(self.b2)\n","        h = 1e-4\n","        \n","        row, column = g_W1.shape\n","        for i in range(row):\n","            for j in range(column):\n","                value = self.W1[i, j]\n","                self.W1[i, j] = value + h\n","                fh1 = self.lossFunction(x, t)\n","                self.W1[i, j] = value - h\n","                fh2 = self.lossFunction(x, t)\n","                g_W1[i, j] = (fh1 - fh2)/(2*h)\n","                self.W1[i, j] = value\n","                \n","        row, column = g_W2.shape\n","        for i in range(row):\n","            for j in range(column):\n","                value = self.W2[i, j]\n","                self.W2[i, j] = value + h\n","                fh1 = self.lossFunction(x, t)\n","                self.W2[i, j] = value - h\n","                fh2 = self.lossFunction(x, t)\n","                g_W2[i, j] = (fh1 - fh2)/(2*h)\n","                self.W2[i, j] = value\n","                \n","        row = g_b1.size\n","        for i in range(row):\n","            value = self.b1[i]\n","            self.b1[i] = value + h\n","            fh1 = self.lossFunction(x, t)\n","            self.b1[i] = value - h\n","            fh2 = self.lossFunction(x, t)\n","            g_b1[i] = (fh1 - fh2)/(2*h)\n","            self.b1[i] = value\n","            \n","        row = g_b2.size\n","        for i in range(row):\n","            value = self.b2[i]\n","            self.b2[i] = value + h\n","            fh1 = self.lossFunction(x, t)\n","            self.b2[i] = value - h\n","            fh2 = self.lossFunction(x, t)\n","            g_b1[i] = (fh1 - fh2)/(2*h)\n","            self.b2[i] = value\n","        \n","        return (g_W1, g_W2, g_b1, g_b2)\n","    \n","    def grad_disc(self, x, t, lr = 1, step = 1):\n","        for _ in range(step):\n","            g_W1, g_W2, g_b1, g_b2 = self.grad(x, t)\n","            self.W1 -= lr*g_W1\n","            self.W2 -= lr*g_W2\n","            self.b1 -= lr*g_b1\n","            self.b2 -= lr*g_b2\n","\n","(x_train, t_train), (x_test, t_test) = \\\n","    load_mnist(flatten=True, normalize=True, one_hot_label=True)\n","    \n","network = TwoLayerNet(x_train.shape[1], 20, t_train.shape[1])\n","batch_size = 100\n","\n","print(\"学習を始めます。最初の精度は{}%です\".format(str(network.accuracy(x_test, t_test)*100)))\n","\n","for i in range(10):\n","    batch_mask = np.random.choice(x_train.shape[0], batch_size)\n","    x_batch = x_train[batch_mask]\n","    t_batch = t_train[batch_mask]\n","    print(\"{}回目の学習中です。\".format(str(i+1)))\n","    network.grad_disc(x_batch, t_batch)\n","    print(\"学習が終わりました。テストします。\")\n","    print(\"テスト中です\")\n","    print(\"テストが終わりました。精度は{}%です\".format(str(network.accuracy(x_test, t_test)*100)))"],"execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-57c58594f6ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpardir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}